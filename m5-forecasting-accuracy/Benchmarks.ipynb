{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import statsmodels.api as sm\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing, ExponentialSmoothing\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "sys.path.append(str(current_dir.parent))\n",
    "from utils import get_competition_data_path, submit\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "plt.rcParams[\"figure.figsize\"] = 20, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path_dict = get_competition_data_path(\"m5-forecasting-accuracy\")\n",
    "competition_path = path_dict.get(\"competition_path\")\n",
    "train_path = path_dict.get(\"train_path\")\n",
    "submission_path = path_dict.get(\"sample_submission_path\")\n",
    "calendar_path = competition_path / \"calendar.csv\"\n",
    "sell_prices_path = competition_path / \"sell_prices.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    \n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>d_5</th>\n",
       "      <th>d_6</th>\n",
       "      <th>d_7</th>\n",
       "      <th>d_8</th>\n",
       "      <th>d_9</th>\n",
       "      <th>d_10</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1904</th>\n",
       "      <th>d_1905</th>\n",
       "      <th>d_1906</th>\n",
       "      <th>d_1907</th>\n",
       "      <th>d_1908</th>\n",
       "      <th>d_1909</th>\n",
       "      <th>d_1910</th>\n",
       "      <th>d_1911</th>\n",
       "      <th>d_1912</th>\n",
       "      <th>d_1913</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_001_CA_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_002_CA_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_003_CA_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_004_CA_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_005_CA_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1913 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    d_1  d_2  d_3  d_4  d_5  d_6  d_7  d_8  d_9  d_10  ...  \\\n",
       "id                                                                     ...   \n",
       "HOBBIES_1_001_CA_1    0    0    0    0    0    0    0    0    0     0  ...   \n",
       "HOBBIES_1_002_CA_1    0    0    0    0    0    0    0    0    0     0  ...   \n",
       "HOBBIES_1_003_CA_1    0    0    0    0    0    0    0    0    0     0  ...   \n",
       "HOBBIES_1_004_CA_1    0    0    0    0    0    0    0    0    0     0  ...   \n",
       "HOBBIES_1_005_CA_1    0    0    0    0    0    0    0    0    0     0  ...   \n",
       "\n",
       "                    d_1904  d_1905  d_1906  d_1907  d_1908  d_1909  d_1910  \\\n",
       "id                                                                           \n",
       "HOBBIES_1_001_CA_1       1       3       0       1       1       1       3   \n",
       "HOBBIES_1_002_CA_1       0       0       0       0       0       1       0   \n",
       "HOBBIES_1_003_CA_1       2       1       2       1       1       1       0   \n",
       "HOBBIES_1_004_CA_1       1       0       5       4       1       0       1   \n",
       "HOBBIES_1_005_CA_1       2       1       1       0       1       1       2   \n",
       "\n",
       "                    d_1911  d_1912  d_1913  \n",
       "id                                          \n",
       "HOBBIES_1_001_CA_1       0       1       1  \n",
       "HOBBIES_1_002_CA_1       0       0       0  \n",
       "HOBBIES_1_003_CA_1       1       1       1  \n",
       "HOBBIES_1_004_CA_1       3       7       2  \n",
       "HOBBIES_1_005_CA_1       2       2       4  \n",
       "\n",
       "[5 rows x 1913 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales = pd.read_csv(train_path)\n",
    "\n",
    "sales = sales.set_index('id').drop(columns=['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'])\n",
    "sales.index = sales.index.to_series().str.rsplit('_', 1, expand=True)[0].rename('id')\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove days that should have no values (Xmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sales = sales.sum(axis=0)\n",
    "outliers = total_sales.loc[total_sales < 10000].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d_331', 'd_697', 'd_1062', 'd_1427', 'd_1792']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = sales.loc[:, ~sales.columns.isin(outliers)]\n",
    "total_sales = total_sales.loc[~total_sales.index.isin(outliers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vals = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_df, y_val_df = sales.iloc[:, :-n_vals], sales.iloc[:, -n_vals:]\n",
    "y_train, y_val = y_train_df.to_numpy(), y_val_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_y_train_df, total_y_val_df = total_sales.iloc[:-n_vals], total_sales.iloc[-n_vals:]\n",
    "total_y_train, total_y_val = total_y_train_df.to_numpy(), total_y_val_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trains = y_train.shape[1]\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Naive\n",
    "- Seasonal Naive\n",
    "    - 7 days\n",
    "    - 28 days\n",
    "    - 365 days\n",
    "- Simple Exponential Smoothing\n",
    "    - $Y_{t + 1} = \\alpha * Y_t + (1 - \\alpha) * Y_{t-1}$\n",
    "    - $\\alpha = [0.1,  0.3]$\n",
    "- Moving Averages\n",
    "    - 7 days\n",
    "    - 28 days\n",
    "    - 365 days\n",
    "- ES (Top-down)\n",
    "    - Last 28 days to estimate the proportion\n",
    "- Arima (Top-down)\n",
    "    - Last 28 days to estimate the proportion\n",
    "- Average of ES and ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive\n",
    "$y_t = y_{t-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_y = y_train[:, -1].reshape(-1, 1)\n",
    "y_pred_naive = np.repeat(last_y, 28, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RMSE for Naive:', rmse(y_val, y_pred_naive))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal Naive\n",
    "- 7 days\n",
    "- 28 days\n",
    "- 365 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_7_y = y_train[:, -7:]\n",
    "y_pred_snaive_7 = np.tile(last_7_y, 4)\n",
    "\n",
    "y_pred_snaive_28 = y_train[:, -28:]\n",
    "\n",
    "y_pred_snaive_365 = y_train[:, -365: -365+28]\n",
    "\n",
    "all_y_pred_snaive = [y_pred_snaive_7, y_pred_snaive_28, y_pred_snaive_365]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RMSE for sNaive lag 7:', rmse(y_val, y_pred_snaive_7))\n",
    "print('RMSE for sNaive lag 28:', rmse(y_val, y_pred_snaive_28))\n",
    "print('RMSE for sNaive lag 365:', rmse(y_val, y_pred_snaive_365))\n",
    "print('RMSE for average sNaive:', rmse(y_val, np.sum(all_y_pred_snaive, axis=0) / 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Moving from Naive prediction to Seasonal Naive already improves the RMSE.\n",
    "- Taking average improves significantly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Exponential Smoothing\n",
    "- $Y_{(t + 1)|t} = \\alpha * Y_t + (1 - \\alpha) * Y_{t|t-1}$\n",
    "- $\\alpha = [0.1,  0.3]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_y_pred_ses = []\n",
    "\n",
    "# Loop through each alpha to generate forecast\n",
    "for alpha in [0.1, 0.2, 0.3]:\n",
    "    # Get empty array to store prediction value\n",
    "    y_pred_ses = np.zeros_like(y_val)\n",
    "    \n",
    "    # Train array to extend period by period\n",
    "    y_train_ses = y_train.copy()\n",
    "    \n",
    "    # Predict period by period\n",
    "    for i in range(n_vals):\n",
    "        # Get the smoothing coefficients\n",
    "        power_arr = np.arange(0, n_trains + i)[::-1]\n",
    "        coeff = (alpha * np.power(alpha, power_arr)).reshape(1, -1)\n",
    "        \n",
    "        # Get predicton\n",
    "        this_ses = np.multiply(y_train_ses, coeff).sum(axis=1)\n",
    "        \n",
    "        # Add back to the array\n",
    "        y_train_ses = np.concatenate([y_train_ses, this_ses.reshape(-1, 1)], axis=1)\n",
    "        y_pred_ses[:, i] = this_ses\n",
    "    \n",
    "    print(f'RMSE for SES with alpha {alpha}:', rmse(y_val, y_pred_ses))\n",
    "    \n",
    "    all_y_pred_ses.append(y_pred_ses)\n",
    "    \n",
    "print(f'RMSE for average SES:', rmse(y_val, np.sum(all_y_pred_ses, axis=0) / 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The SES doesn't work so well compared to other benchmarks\n",
    "- Its usage is more appropriate for data with no clear trend and seasonality\n",
    "- The saels data that we have clearly exhibits trend and seasonality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Averages\n",
    "- 7 days\n",
    "- 28 days\n",
    "- 365 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_y_pred_ma = []\n",
    "\n",
    "# Loop through each alpha to generate forecast\n",
    "for window in [7, 28, 365]:\n",
    "    # Get empty array to store prediction value\n",
    "    y_pred_ma = np.zeros_like(y_val)\n",
    "    \n",
    "    # Train array to extend period by period\n",
    "    y_train_ma = y_train.copy()\n",
    "    \n",
    "    # Predict period by period\n",
    "    for i in range(n_vals):\n",
    "        # Get predicton\n",
    "        this_ma = y_train_ma[:, -window:].mean(axis=1)\n",
    "        \n",
    "        # Add back to the array\n",
    "        y_train_ma = np.concatenate([y_train_ma, this_ma.reshape(-1, 1)], axis=1)\n",
    "        y_pred_ma[:, i] = this_ma\n",
    "    \n",
    "    print(f'RMSE for MA with window {window}:', rmse(y_val, y_pred_ma))\n",
    "    \n",
    "    all_y_pred_ma.append(y_pred_ma)\n",
    "    \n",
    "print(f'RMSE for average MA:', rmse(y_val, np.sum(all_y_pred_ma, axis=0) / 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Moving Average is able to take in account the trend and performs pretty well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ES and SARIMA (Top-down)\n",
    "- Estimate the total sales with ES and ARIMA\n",
    "- Trickle down using proportion of sales to get the lowest level\n",
    "- Last 28 days to estimate the proportion\n",
    "- Average of ES and ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sales.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion = np.divide(y_train, total_y_train)[:, -28:].mean(axis=1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_y_pred_es = []\n",
    "for seasonality in [7, 28, 365]:\n",
    "    es = ExponentialSmoothing(total_y_train, trend='add', damped=True, seasonal='add', seasonal_periods=seasonality)\n",
    "    es.fit()\n",
    "    pred_es = es.predict(es.params, start=n_trains + 1, end=n_trains + 28)\n",
    "    y_pred_es = np.multiply(proportion, pred_es)\n",
    "    \n",
    "    print(f'RMSE for top-down ES with seasonality cycle of {seasonality} days:', rmse(y_val, y_pred_es))\n",
    "    \n",
    "    all_y_pred_es.append(y_pred_es)\n",
    "    \n",
    "print(f'RMSE for average top-down ES:', rmse(y_val, np.sum(all_y_pred_es, axis=0) / 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SARIMAX(\n",
    "    total_y_train,\n",
    "    order=(1, 1, 1),\n",
    "    seasonal_order=(1, 1, 1, 7),\n",
    "    enforce_stationarity=False,\n",
    "    enforce_invertibility=False,\n",
    ")\n",
    "result = model.fit()\n",
    "print(results.summary().tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.plot_diagnostics(figsize=(16, 8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_arima = results.predict(start=n_trains + 1, end=n_trains + 28)\n",
    "y_pred_sarima = np.multiply(proportion, pred_arima)\n",
    "\n",
    "print(f'RMSE for SARIMA:', rmse(y_val, y_pred_sarima))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
